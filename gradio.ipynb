{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4849320,"sourceType":"datasetVersion","datasetId":2807884}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:28:17.698401Z","iopub.execute_input":"2024-12-03T17:28:17.698831Z","iopub.status.idle":"2024-12-03T17:28:27.863785Z","shell.execute_reply.started":"2024-12-03T17:28:17.698798Z","shell.execute_reply":"2024-12-03T17:28:27.862511Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gradio in /opt/conda/lib/python3.10/site-packages (5.7.1)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nRequirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.115.5)\nRequirement already satisfied: ffmpy in /opt/conda/lib/python3.10/site-packages (from gradio) (0.4.0)\nRequirement already satisfied: gradio-client==1.5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.5.0)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.26.2)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\nRequirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.3)\nRequirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.2)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart==0.0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.12)\nRequirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\nRequirement already satisfied: ruff>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.8.1)\nRequirement already satisfied: safehttpx<1.0,>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.1.6)\nRequirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.10.0)\nRequirement already satisfied: starlette<1.0,>=0.40.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.41.3)\nRequirement already satisfied: tomlkit==0.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.0)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.0->gradio) (2024.9.0)\nRequirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.5.0->gradio) (12.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.15.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gradio) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.27.1)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (1.26.18)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# import shutil\n\n# def clean_output_folder(output_folder):\n#     if os.path.exists(output_folder):\n#         shutil.rmtree(output_folder)  # Remove the existing directory and its contents\n#     os.makedirs(output_folder)\n\n# clean_output_folder(\"/kaggle/working/temp_frames\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:35:19.985702Z","iopub.execute_input":"2024-12-03T17:35:19.986101Z","iopub.status.idle":"2024-12-03T17:35:19.998124Z","shell.execute_reply.started":"2024-12-03T17:35:19.986065Z","shell.execute_reply":"2024-12-03T17:35:19.996776Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# def extract_frames(video_path, output_folder=\"temp_frames\", frame_size=(64, 64)):\n#     \"\"\"\n#     Extract frames from a single video, resize, and save them to a specified directory.\n#     \"\"\"\n#     # Use /kaggle/working/temp_frames to ensure it's a writable directory\n#     output_folder = os.path.join(\"/kaggle/working\", output_folder)\n\n#     # Create the directory if it doesn't exist\n#     if not os.path.exists(output_folder):\n#         os.makedirs(output_folder)\n#         print(f\"Directory created: {output_folder}\")\n#     else:\n#         print(f\"Directory already exists: {output_folder}\")\n\n#     if os.access(output_folder, os.W_OK):\n#         print(f\"Directory is writable: {output_folder}\")\n#     else:\n#         print(f\"Directory is NOT writable: {output_folder}\")\n\n    \n#     video_capture = cv2.VideoCapture(video_path)\n#     frame_count = 0\n#     success = True\n#     extracted_frames = []\n\n#     while success:\n#         success, frame = video_capture.read()\n#         if success:\n#             # Resize and convert to grayscale\n#             frame = cv2.resize(frame, frame_size, interpolation=cv2.INTER_AREA)\n#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n#             # Save frame\n#             frame_filename = f\"frame_{frame_count:05d}.jpg\"\n#             frame_filepath = os.path.join(output_folder, frame_filename)\n#             cv2.imwrite(frame_filepath, frame)\n\n#             extracted_frames.append(frame_filepath)\n#             frame_count += 1\n\n#     video_capture.release()\n#     return extracted_frames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:32:20.167045Z","iopub.execute_input":"2024-12-03T17:32:20.168073Z","iopub.status.idle":"2024-12-03T17:32:20.175453Z","shell.execute_reply.started":"2024-12-03T17:32:20.168029Z","shell.execute_reply":"2024-12-03T17:32:20.174288Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# video_path = \"/kaggle/input/ucf101-action-recognition/test/BenchPress/v_BenchPress_g01_c02.avi\"  # Update this to a valid video path\n# frames = extract_frames(video_path, output_folder=\"temp_frames\")\n# print(f\"Extracted {len(frames)} frames to temp_frames.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:34:28.986937Z","iopub.execute_input":"2024-12-03T17:34:28.987368Z","iopub.status.idle":"2024-12-03T17:34:29.219413Z","shell.execute_reply.started":"2024-12-03T17:34:28.987335Z","shell.execute_reply":"2024-12-03T17:34:29.218217Z"}},"outputs":[{"name":"stdout","text":"Extracted 180 frames to temp_frames.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import gradio as gr\nimport cv2\nimport os\n\n# Function to extract frames\ndef extract_frames(video_path, output_folder=\"/kaggle/working/temp_frames\", frame_size=(64, 64)):\n    \"\"\"\n    Extract frames from a video, resize to 64x64, and save to the specified folder.\n\n    Parameters:\n        video_path (str): Path to the video file.\n        output_folder (str): Directory to save extracted frames.\n        frame_size (tuple): Target frame size (width, height).\n\n    Returns:\n        list: List of file paths to the extracted frames.\n    \"\"\"\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n        print(f\"Directory created: {output_folder}\")\n    else:\n        print(f\"Directory already exists: {output_folder}\")\n\n    video_capture = cv2.VideoCapture(video_path)\n    frame_count = 0\n    success = True\n    extracted_frames = []\n\n    while success:\n        success, frame = video_capture.read()\n        if success:\n            # Resize and convert to grayscale\n            frame = cv2.resize(frame, frame_size, interpolation=cv2.INTER_AREA)\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\n            # Save frame as image\n            frame_filename = f\"frame_{frame_count:05d}.jpg\"\n            frame_filepath = os.path.join(output_folder, frame_filename)\n            cv2.imwrite(frame_filepath, frame)\n\n            extracted_frames.append(frame_filepath)\n            frame_count += 1\n\n    video_capture.release()\n    print(f\"Extracted {len(extracted_frames)} frames.\")\n    return extracted_frames\n\n\n# Function to process video input\ndef process_video(uploaded_video, selected_sample):\n    \"\"\"\n    Process the uploaded or selected video and extract frames.\n\n    Parameters:\n        uploaded_video (Gradio file): Uploaded video by user.\n        selected_sample (str): Path to a selected video from test dataset.\n\n    Returns:\n        list: List of paths to extracted frames.\n    \"\"\"\n    if uploaded_video is not None:\n        # Save uploaded video to /kaggle/working/temp_videos\n        temp_dir = \"/kaggle/working/temp_videos\"\n        os.makedirs(temp_dir, exist_ok=True)\n        video_path = os.path.join(temp_dir, uploaded_video.name)\n        with open(video_path, \"wb\") as f:\n            f.write(uploaded_video.read())\n        print(f\"Uploaded video saved at: {video_path}\")\n    elif selected_sample is not None:\n        # Use selected sample video path\n        video_path = selected_sample\n        print(f\"Selected sample video path: {video_path}\")\n    else:\n        print(\"No video input provided.\")\n        return []\n\n    # Extract frames\n    extracted_frames = extract_frames(video_path, output_folder=\"/kaggle/working/temp_frames\")\n    return extracted_frames\n\n\n# Video paths for Dropdown (example paths)\nvideo_paths = [\n    \"/kaggle/input/ucf101-action-recognition/test/JumpingJack/k_JumpingJack_g12_c04.avi\",\n    \"/kaggle/input/ucf101-action-recognition/test/Walking/k_Walking_g12_c04.avi\",\n    \"/kaggle/input/ucf101-action-recognition/test/Biking/k_Biking_g12_c04.avi\",\n]\n\n# Gradio Interface\nwith gr.Blocks() as demo:\n    gr.Markdown(\"# Video Processing Interface\")\n    gr.Markdown(\"Upload a video or select a video from the test folder to process and extract frames.\")\n\n    with gr.Row():\n        with gr.Column():\n            # Upload option\n            video_input = gr.File(label=\"Upload Video\", file_types=[\".mp4\", \".avi\", \".mkv\"])\n            # Dropdown selection\n            sample_input = gr.Dropdown(\n                choices=video_paths,\n                label=\"Or Select a Video from Test Folder\",\n                interactive=True\n            )\n            run_button = gr.Button(\"Run Models\")\n        with gr.Column():\n            with gr.Tab(\"Model 1\"):\n                gr.Markdown(\"### Model 1 Results\")\n                frames_output1 = gr.Gallery(label=\"Extracted Frames\", columns=5, height=\"auto\")  # For testing\n                video_output1 = gr.Video(label=\"Final Video\")  # Placeholder\n                time_output1 = gr.Textbox(label=\"Inference Time\")  # Placeholder\n            with gr.Tab(\"Model 2\"):\n                gr.Markdown(\"### Model 2 Results\")\n                frames_output2 = gr.Gallery(label=\"Generated Frames\", columns=2, height=\"auto\")\n                video_output2 = gr.Video(label=\"Final Video\")\n                time_output2 = gr.Textbox(label=\"Inference Time\")\n            with gr.Tab(\"Model 3\"):\n                gr.Markdown(\"### Model 3 Results\")\n                frames_output3 = gr.Gallery(label=\"Generated Frames\", columns=2, height=\"auto\")\n                video_output3 = gr.Video(label=\"Final Video\")\n                time_output3 = gr.Textbox(label=\"Inference Time\")\n\n    # Handle button click\n    def handle_run(uploaded_video, selected_sample):\n        frames = process_video(uploaded_video, selected_sample)\n        return frames, None, \"0.0 seconds\", [], None, None, [], None, None\n\n    run_button.click(\n        handle_run,\n        inputs=[video_input, sample_input],\n        outputs=[\n            frames_output1, video_output1, time_output1,\n            frames_output2, video_output2, time_output2,\n            frames_output3, video_output3, time_output3\n        ]\n    )\n\n    gr.Markdown(\"© 2024 Your Application\")\n\n# Launch the application\ndemo.launch()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-03T17:48:04.618616Z","iopub.execute_input":"2024-12-03T17:48:04.619074Z","iopub.status.idle":"2024-12-03T17:48:06.975743Z","shell.execute_reply.started":"2024-12-03T17:48:04.619037Z","shell.execute_reply":"2024-12-03T17:48:06.974603Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7864\nKaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n\n* Running on public URL: https://00921f2dd38ee6c809.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://00921f2dd38ee6c809.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"Selected sample video path: /kaggle/input/ucf101-action-recognition/test/JumpingJack/k_JumpingJack_g12_c04.avi\nDirectory already exists: /kaggle/working/temp_frames\nExtracted 0 frames.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}